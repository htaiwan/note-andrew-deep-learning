
## Week 1. Foundations of Convolutional Neural Networks
### 1.1 computer vision
> [1.1.1 機器視覺的3個主要問題?](#1.1.1)
> 
> [1.1.2 深度學習在處理大型圖片所遇到的困難?](#1.1.2)

### 1.2 Edge Detection Example
> [1.2.1 filter的功用?](#1.2.1)
> 
> [1.2.2 如何由filter生成出feature map?](#1.2.2)

### 1.3 More Edge Detection

> [1.3.1 feature map的意義?](#1.3.1)
> 
> [1.3.2 客製化的filter?](#1.3.2)

### 1.4 Padding

> [1.4.1 padding的意義?](#1.4.1)
> 
> [1.4.2 couvolution的type?](#1.4.2)

### 1.5 Strided Convolutions

> [1.5.1 Strided Convolutions的意義?](#1.5.1)
> 
> [1.5.2 feature map長寬的計算公式?](#1.5.2)

### 1.6 Convolutions Over Volume

> [1.6.1 什麼是Volume?](#1.6.1)
> 
> [1.6.2 理解volume convolution的計算?](#1.6.2)
> 
> [1.6.3 理解Multiple filters的計算?](#1.6.3)

### 1.7 One Layer of a Convolutional Network

> [1.7.1 理解conv-layer的計算過程?](#1.7.1)
> 
> [1.7.2 如何計算filter也就是weights（parameters）的數量?](#1.7.2)
> 
> [1.7.3 理解conv-layer設計在計算效率的優勢?](#1.7.3)

### 1.8 Simple Convolutional Network Example

> [1.8.1 如何構建一個簡單的onvolutional Network?](#1.8.1)

### 1.9 Pooling Layers

> [1.9.1 Max pooling的功用?](#1.9.1)
> 
> [1.9.2 什麼時候會用 Avg pooling?](#1.9.2)
> 
> [1.9.3 為什麼需要pooling layer?](#1.9.3)

### 1.10 CNN Example

> [1.10.1 了解 LeNet-5的主要結構?](1.10.1)
> 
> [1.10.2 如何計算每一層parameters的數量?](1.10.2)

### 1.11 Why Convolutions?

> [1.11.1 為什麼處理圖片時，CNN的效果優於傳統的NN?](#1.11.1)
> 
> [1.11.2 什麼是parameter sharing?](#1.11.2)
> 
> [1.11.3 什麼是sparsity of connections?](#1.11.3)

---

## Answers: 

<h3 id="1.1.1">1.1.1 機器視覺的3個主要問題?</h3>

> 在這裡所學到的三個任務：圖片分類，物體識別，風格融合。 

<h3 id="1.1.2">1.1.2 深度學習在處理大型圖片所遇到的困難?</h3>

> 大型圖片所產生的parameters龐大，導致計算量成本也大大提升。

<h3 id="1.2.1">1.2.1 filter的功用?</h3>

> * 一個filter即是一組weights，代表一個特徵。
> * 用特徵去掃描整張原圖的每一個局部，確認每一個局部是否有這個特徵存在。

<h3 id="1.2.2">1.2.2 如何由filter生成出feature map?</h3>

> * 利用filter跟原圖進行掃描，由convolution operation產生。
> * convolution operation：filter跟原圖: 點對點相乘 -> 相加 -> 得到一個評估值 -> 平移(右，下) -> 重複計算。

<h3 id="1.3.1">1.3.1 feature map的意義?</h3>

> * feature map = CNN con layer output = matrix of neurons
> * 每一個neuron嘗試從原圖中的一部分確認某種特徵是否存在。
> * feature map中的所有neuron都對應都同一特徵。
> * 對原圖針對某種特徵(filter)的抽象化的變形(亮與不亮)。

<h3 id="1.3.2">1.3.2 客製化的filter?</h3>

> * CNN模型通過大量訓練，不斷更新weights，幫助我們量身制定filter。


<h3 id="1.4.1">1.4.1 padding的意義?</h3>

> > * 因為convolution operation會讓新合成的圖片越變越小，所以層數越多，圖片越小，導致無法增加層數，且最邊沿的數據，只被使用一次就被丟失了。
> > * padding，保留pixel數量，讓模型可以足夠深。

<h3 id="1.4.2">1.4.2 couvolution的type?</h3>

> * Valid couvolution: 無padding。
> * Same couvolution: 有padding。

<h3 id="1.5.1">1.5.1 Strided Convolutions的意義?</h3>

> * Convolution operation without padding: filter, 單格平移，新圖片縮小。
> * Convolution operation with padding： padding 補齊外圍pixel，新圖片大小保持不變。
> * Strided Convolution：跳格平移（2格或更多），新圖片加倍縮小，避免重複計算。

<h3 id="1.5.2">1.5.2 feature map長寬的計算公式?</h3>

> * no padding: n - f + 1
> * padding: n + 2p - f + 1
> * stride with padding: (n + 2p - f)/s + 1
> * 出格: np.floor((n + 2p - f)/s + 1)

<h3 id="1.6.1">1.6.1 什麼是Volume?</h3>

> * 從原本的2D image延伸到3D image(3 channels RGB)。

<h3 id="1.6.2">1.6.2 理解volume convolution的計算?</h3>

> ![1](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/1.png)
> 
> * filter變立體化，每個filter的output的feature map仍是2D

<h3 id="1.6.3">1.6.3 理解Multiple filters的計算?</h3>

> ![2](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/2.png)
> 
> * 多個filter的output的feature map疊加後變成3D

<h3 id="1.7.1">1.7.1 理解conv-layer的計算過程?</h3>

> ![3](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/3.png)
> 
> * 跟NN計算方式一樣，WX+b。

<h3 id="1.7.2">1.7.2 如何計算filter也就是weights（parameters）的數量?</h3>

> ![4](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/4.png)

<h3 id="1.7.3">1.7.3 理解conv-layer設計在計算效率的優勢?</h3>

> * parameters數量決定模型的大小跟計算量的的需求，同樣處理同一張圖，CNN所需要的parameters遠小於NN，計算量也更小。


<h3 id="1.8.1">1.8.1 如何構建一個簡單的onvolutional Network?</h3>

> ![5](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/5.png)


<h3 id="1.9.1">1.9.1 Max pooling?</h3>

> ![6](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/6.png)
> 
> * 只保留下最大的特徵值，強化特徵的呈現。

<h3 id="1.9.2">1.9.2 Avg pooling?</h3>

> * 跟Max很像，只是換成取平均值。
 
<h3 id="1.9.3">1.9.3 為什麼需要pooling layer?</h3>

> * 縮小特徵值的規模，節省計算量。
> * 需要hyperparameters, 但不產生parameters。


<h3 id="1.10.1">1.10.1 了解 LeNet-5的主要結構?</h3>

> ![7](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/7.png)

<h3 id="1.10.2">1.10.2 如何計算每一層parameters的數量?</h3>

> ![8](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/8.png)
> 
> * parameters 數量 = （filter_w x filter_h + 1) x num_filters

<h3 id="1.11.1">1.11.1 為什麼處理圖片時，CNN的效果優於傳統的NN?</h3>

> ![9](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/9.png)
> 
> * Convolution layer的parameter數量遠小於Full connected layer。
 
<h3 id="1.11.2">1.11.2 什麼是parameter sharing?</h3>

> ![10](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/10.png)
>
> * 共享同一個filter。 

<h3 id="1.11.3">1.11.3 什麼是sparsity of connections?</h3>

> * feature map中的每一個值，只需要參考原圖的某一塊資訊，不用將原圖中全部資訊都加入考慮。 


