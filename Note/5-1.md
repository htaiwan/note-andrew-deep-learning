## Week 1. Recurrent Neural Networks

### 1.1 Why sequence models?
> [1.1.1 什麼是sequence data?](#1.1.1)
> 

### 1.2 Notation
> [1.2.1 如何表達sequence data中的任一個element](#1.2.1)
> 

### 1.3 Recurrent Neural Network Model
> [1.3.1 為什麼要有RNN](#1.3.1)
> 
> [1.3.2 RNN的基本架構](#1.3.2)
> 
> [1.3.3 RNN的forward progagation的數學公式](#1.3.3)
> 
> [1.3.4 RNN的公式簡化](#1.3.4)

### 1.4 Backpropagation through time
> [1.4.1 RNN獨有的Backpropagation through time](#1.4.1)
> 

### 1.5 Different types of RNNs
> [1.5.1 不同type的sequence data所對應不同type的RNN](#1.5.1)
> 

### 1.6 Language model and sequence generation
> [1.6.1 什麼是Language modelling](#1.6.1)
> 
> [1.6.2 字典中特殊的符號](#1.6.2)
> 
> [1.6.3 理解RNN是如何處理語言生成](#1.6.3)


### 1.7 Sampling novel sequences
> [1.7.1 如何用訓練好的RNN model來生成句子](#1.7.1)
> 
> [1.7.2 Character-level language model的優缺點](#1.7.2)

### 1.8 Vanishing gradients with RNNs
> [1.8.1 理解RNN中Vanishing gradients是怎樣產生的](#1.8.1)
> 

### 1.9 Gated Recurrent Unit (GRU)
> [1.9.1 GRU的設計原理(簡易版,完整版)](#1.9.1)
> 
> [1.9.2 GRU如何解決RNN中Vanishing gradients的問題](#1.9.2)

### 1.10 Long Short Term Memory (LSTM)
> [1.10.1 LSTM的設計原理](#1.10.1)
>
> [1.10.2 GRU,LSTM的比較](#1.10.2)

### 1.11 Bidirectional RNN
> [1.11.1 Bidirectional RNN所想要解決的問題是什麼](#1.11.1)
>
> [1.11.2 Bidirectional RNN的設計原理，優缺點](#1.11.2)

### 1.12 Deep RNNs

> [1.12.1 如何構造深層RNN模型?](#1.12.1)

---

## Answers: 

