
## Week 2. Deep convolutional models: case studies

### Case studies

### 2.1 Why look at case studies?

> [2.1.1 為什麼要學習一些經典模型結構?]()

### 2.2 Classic Networks 

> [2.2.1 LeNet-5結構?]()
> 
> [2.2.2 AlexNet結構?]()
> 
> [2.2.3 VGG結構?]()

### 2.3 ResNets

> [2.3.1 為什麼深度模型結構很難訓練?]()
> 
> [2.3.2 什麼是residual block?]()
> 
> [2.3.3 理解plain network與ResNet的效果對比?]()

### 2.4 Why ResNets Work

> [2.4.1 ResNet的skip connection是如何解決梯度消失和爆炸的问题?]()

### 2.5 Networks in Networks and 1x1 Convolutions

> [2.5.1 理解network in network的結構?]()
> 
> [2.5.2 理解network in network的功用?]()

### 2.6 Inception Network Motivation

> [2.6.1 理解inception的核心?]()
> 
> [2.6.2 理解inception的成本問題是如何解決?]()

### 2.7 Inception Network

> [2.7.1 理解一個完整的Inception module?]()
> 
> [2.7.2 如何理解中間預測層的功用?]()


---
---

### Practical advices for using ConvNets
### 2.8 Using Open-Source Implementation 

### 2.9 Transfer Learning 

> [2.9.1 為什麼需要Transfer Learning?]()
> 
> [2.9.2 如何讓transfer learning的訓練速度加快?]()
> 

### 2.10 Data Augmentation

> [2.10.1 常見的擴充樣本圖片數量的方法?]()
> 

### 2.11 State of Computer Vision 

> [2.11.1 模型的知識來源?]()
> 
> [2.11.2 理解ensembling與multi-crop方法及代價?]()


---
