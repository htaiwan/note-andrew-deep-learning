## Week 1. ML Strategy (1)

### 1.1 Why ML Strategy?

> [1.1.1  為什麼需要學ML Strategy](#1.1.1)

### 1.2 Orthogonalization

> [1.2.1  什麼是Orthogonalization](#1.2.1)
> 
> [1.2.2  如何尋找要調試knobs](#1.2.2)

### 1.3 Single number evaluation metric

> [1.3.1  什麼是Single number evaluation metric](#1.3.1)

### 1.4 Satisficing and Optimizing metric

> [1.4.1  什麼是Satisficing and Optimizing metric](#1.4.1)

### 1.5 Train/dev/test distributions

> [1.5.1  Train/dev/test 錯誤配置的例子](#1.5.1)

### 1.6 Size of the dev and test sets

> [1.6.1  如何分配數據集](#1.6.1)
> 
> [1.6.2  如何決定test sets](#1.6.2)

### 1.7 When to change dev/test sets and metrics

> [1.7.1  什麼情況下會修改dev/test sets](#1.7.1)
> 
> [1.7.2  什麼情況下會修改metrics](#1.7.2)

### 1.8 Why human-level performance?

> [1.8.1  為什麼模型要對比人類的標準](#1.8.1)
> 
> [1.8.2  當模型的效能還比人類差時，有哪些方法可以幫助模型](#1.8.2)

### 1.9 Avoidable bias

### 1.10 Understanding human-level performance

> [1.10.1  human-level error 跟 Bayes error的關係](#1.10.1)

### 1.11 Surpassing human-level performance

> [1.11.1  機器超越人類的領域](#1.11.1)

### 1.12 Improving your model performance

> [1.12.1  改善模型的方法](#1.12.1)


---

## Answers: 

<h3 id="1.1.1">1.1.1 為什麼需要學ML Strategy</h3>

> * 因為可以幫助改善模型效能的方法有很多(ex. 更多的data,更有效能的演算法, 更好的模型架構)，如何有策略是選擇適當的方法，幫助我們有效率的是改善模型效能。

<h3 id="1.2.1">1.2.1 什麼是Orthogonalization</h3>

> * 每個特徵應該要有單獨的控制。
> * 如果一個knob控制了兩個特徵，那就不是Orthogonalization。

<h3 id="1.2.2">1.2.2 如何尋找要調試knobs</h3>

> ![136](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/136.png)
> 
> * 根據數據集來逐步調適(Training -> dev -> test -> real world)。

<h3 id="1.3.1">1.3.1 什麼是Single number evaluation metric</h3>

> ![137](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/137.png)
> 
> * 因為percision & recall 彼此互相影響，引進F1 Score更可以客觀比較模型的效能。

<h3 id="1.4.1">1.4.1 什麼是Satisficing and Optimizing metric</h3>

> ![138](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/138.png)
> 
> * 當某些狀況下，無法決定Single number evaluation metric，那就要靠Satisficing and Optimizing metric。
> * Optimizing matrix: 主要衡量標準，要越精準越好。
> * Satisficing matrix: 次要衡量標準，只要可以達到某個規定的標準即可。

<h3 id="1.5.1">1.5.1 Train/dev/test 錯誤配置的例子</h3>

> ![139](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/139.png)
> 
> * **dev/test的分佈要相同，且要盡可能可以reflect真實世界的現實數據**

<h3 id="1.6.1">1.6.1 如何分配數據集</h3>

> ![140](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/140.png)
> 

<h3 id="1.6.2">1.6.2 如何決定test sets</h3>

> * training set: 目標是訓練模型，越大越好。
> * dev set: 目標是比較模型，不用很大。
> * test set: 目標是評估模型，**數據量大小，是依據是否可以確保是有一個hidg confidence的針對未來所有會面對到現實數據的效果評估。**


<h3 id="1.7.1">1.7.1 什麼情況下會修改dev/test sets</h3>

> ![142](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/142.png)
> 

<h3 id="1.7.2">1.7.2 什麼情況下會修改metrics</h3>

> ![141](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/141.png)
> 

<h3 id="1.8.1">1.8.1 為什麼模型要對比人類的標準</h3>

> ![143](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/143.png)
> 

<h3 id="1.8.2">1.8.2 當模型的效能還比人類差時，有哪些方法可以幫助模型</h3>

> ![144](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/144.png)
> 

<h3 id="1.10.1">1.10.1 human-level error 跟 Bayes error的關係</h3>

> ![145](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/145.png)
> 

<h3 id="1.11.1">1.11.1 機器超越人類的領域</h3>

> ![146](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/146.png)
> 
> * **一但機器在某個領域的能力超越人類，就很難再靠人工的方式來幫助機器更加優越。**

<h3 id="1.12.1">1.12.1 改善模型的方法</h3>

> ![147](https://github.com/htaiwan/note-andrew-deep-learning/blob/master/Asset/147.png)
>

